# S.O.F.I.E. Backend Configuration
# Copy this file to .env and configure your settings

# Server Configuration
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development

# LLaMA Configuration
LLAMA_MODEL_PATH=models/llama-2-7b-chat.gguf
LLAMA_N_CTX=2048
LLAMA_N_THREADS=4
LLAMA_TEMPERATURE=0.7

# Privacy & Consent
REQUIRE_CONSENT=true
CONSENT_EXPIRY_HOURS=24
LOG_LEVEL=INFO

# CORS (for web clients)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173
